# ğŸŒ± FarmOG Station
**Off-Grid Agricultural Intelligence System**

> Multi-sensor disease detection & crop monitoring for small farmers.
> Powered by AI. Runs anywhere. No internet required.

---

## ğŸ¯ Mission

Help small farmers make data-driven decisions using:
- ğŸ“· **Computer Vision** - Detect plant diseases from leaf images
- ğŸ“Š **Sensor Fusion** - Monitor soil, weather, and environmental conditions  
- ğŸ¤– **AI Agents** - Cross-validate diagnosis & provide actionable recommendations
- ğŸ”‹ **Off-Grid** - Solar-powered, LoRa connectivity, edge AI

---

## ğŸ† Project Highlights

- **98.74% accuracy**: Best-in-class ResNet50V2 model for disease detection
- **Multi-modal fusion**: Vision + sensors cross-validate for robust diagnosis
- **Early warning system**: Detect disease-favorable conditions before symptoms appear
- **Three detection modes**: Vision Only, Sensor Only, Full Fusion
- **Edge deployment**: Runs on Raspberry Pi (TensorFlow Lite optimized)
- **Real-world ready**: Designed for harsh farming environments with limited connectivity

---

## ğŸ§  Models

### 1. Disease Vision Classifier
**Three architectures trained and compared:**

| Model | Accuracy | Parameters | Best Use Case |
|-------|----------|------------|---------------|
| **ResNet50V2** | **98.74%** | 25M | Production (highest accuracy) |
| EfficientNetB0 | 93.37% | 5.3M | Balanced performance |
| MobileNetV2 | 90.05% | 3.5M | Edge devices (Raspberry Pi) |

- **Dataset**: 87K images, 10 tomato disease classes
- **Training**: Transfer learning with custom preprocessing per architecture
- **Deployment**: ResNet50V2 for web app, MobileNetV2 for edge (TFLite)
- **Inference**: <100ms (MobileNetV2 on Raspberry Pi 4)

### 2. Sensor Pattern Matcher
- **Input**: Air temp/humidity, soil moisture, rainfall, irrigation method
- **Output**: Disease risk scores (0-100%) + environmental diagnosis
- **Method**: Rule-based disease signatures with weighted scoring
- **Coverage**: 9 disease signatures + healthy baseline

### 3. Fusion System
- **Cross-validation**: Vision â†” Sensor agreement with confidence weighting
- **Confidence scoring**: 0-100% with uncertainty quantification
- **Modes**:
  - **CONFIRMED**: Vision + Sensor agree (high confidence diagnosis)
  - **EARLY_WARNING**: Sensor alerts before visual symptoms
  - **CONFLICT**: Disagreement between modalities (needs review)
  - **LOW_CONFIDENCE**: Uncertain diagnosis

---

## ğŸš€ Quick Start

### Installation
```bash
# Clone repo
git clone https://github.com/diogosimoez/farmog-station.git
cd farmog-station

# Setup environment
conda create -n farmog python=3.10
conda activate farmog
pip install -r requirements.txt
```

### Run the App
```bash
# Option 1: Streamlit command
streamlit run app/app.py

# Option 2: Windows batch file
RUN_APP.bat
```

### Demo the System
The app has 3 detection modes:

1. **Vision Only**: Upload a plant image â†’ Get disease diagnosis
2. **Sensor Only**: Input environmental data â†’ Get risk assessment
3. **Vision + Sensor Fusion**: Both inputs â†’ Cross-validated diagnosis

See `HOW_TO_DEMO.md` for detailed walkthrough

---

## ğŸ“Š System Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         FARMOG STATION ECOSYSTEM            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  ğŸ“· Vision Input          ğŸ“Š Sensor Input   â”‚
â”‚  (Plant images)           (Soil/Weather)    â”‚
â”‚         â”‚                       â”‚           â”‚
â”‚         â–¼                       â–¼           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ ResNet50V2  â”‚        â”‚ Disease     â”‚    â”‚
â”‚  â”‚ 98.74% Acc  â”‚        â”‚ Signatures  â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚         â”‚                       â”‚           â”‚
â”‚         â”‚ Predictions      Risk Scores â”‚   â”‚
â”‚         â”‚ (0-100%)         (0-100%)    â”‚   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                 â–¼                           â”‚
â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â”‚
â”‚         â”‚ FUSION ENGINE â”‚                   â”‚
â”‚         â”‚ Cross-validateâ”‚                   â”‚
â”‚         â”‚ & Score       â”‚                   â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                 â”‚                           â”‚
â”‚                 â–¼                           â”‚
â”‚    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚
â”‚    â”‚ Final Diagnosis        â”‚              â”‚
â”‚    â”‚ â€¢ Disease detected     â”‚              â”‚
â”‚    â”‚ â€¢ Confidence (0-100%)  â”‚              â”‚
â”‚    â”‚ â€¢ Status (CONFIRMED/   â”‚              â”‚
â”‚    â”‚   EARLY_WARNING/etc)   â”‚              â”‚
â”‚    â”‚ â€¢ Root cause           â”‚              â”‚
â”‚    â”‚ â€¢ Corrective actions   â”‚              â”‚
â”‚    â”‚ â€¢ Prevention tips      â”‚              â”‚
â”‚    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Academic Project

**Course**: Data Science & Machine Learning  
**Focus**: Multi-modal learning, computer vision, IoT sensor fusion  
**Duration**: 2 weeks 
**Status**: MVP complete âœ…

---

## ğŸ› ï¸ Tech Stack

- **ML/AI**: TensorFlow, Keras, scikit-learn
- **Vision**: MobileNetV2, TensorFlow Lite
- **Data**: Pandas, NumPy
- **Viz**: Matplotlib, Seaborn, Plotly
- **App**: Streamlit
- **Deploy**: Raspberry Pi 4, Docker (planned)

---

## ğŸ“ Project Structure
```
farmog-station/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ app.py                      # Streamlit dashboard (3 detection modes)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ fusion_engine.py            # Multi-modal fusion logic
â”‚   â”œâ”€â”€ disease_siganture.py        # Disease signatures database
â”‚   â”œâ”€â”€ sensor_matcher.py           # Environmental risk scoring
â”‚   â””â”€â”€ utils.py                    # Helper functions
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_EDA_diseases_model.ipynb            # Dataset exploration
â”‚   â”œâ”€â”€ 03_train_efficientnet_FIXED.ipynb     # EfficientNet training
â”‚   â”œâ”€â”€ 04_train_resnet50v2_FIXED.ipynb       # ResNet50V2 training
â”‚   â”œâ”€â”€ 05_model_comparison_final.ipynb       # Model comparison
â”‚   â”œâ”€â”€ 06_fusion_system_demo.ipynb           # Fusion testing
â”‚   â”œâ”€â”€ 07_model_evaluation.ipynb             # Metrics & confusion matrix
â”‚   â”œâ”€â”€ 08_convert_to_tflite.ipynb            # Edge deployment prep
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ farmog_resnet50v2_classifier.h5   # Main production model
â”‚   â”‚   â”œâ”€â”€ class_names.json                  # Disease class mapping
â”‚   â”‚   â”œâ”€â”€ resnet50v2_metadata.json          # Training metadata
â”‚   â”‚   â””â”€â”€ evaluation_report.json            # Performance metrics
â”‚   â””â”€â”€ docs/                                 # Generated visualizations
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                        # Dataset (87K images, 10 classes)
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ RUN_APP.bat                     # Windows launcher
```

---

## ğŸŒ Real-World Deployment Plan

### Phase 1: Academic MVP (2 weeks) âœ…
- Vision model trained
- Sensor fusion logic
- Demo dashboard

### Phase 2: Hardware Prototype (Month 1-3)
- Raspberry Pi integration
- LoRa communication
- Solar power system

### Phase 3: Field Testing (Month 4-6)
- Deploy 5-10 beta units
- Real farmer feedback
- Model refinement

### Phase 4: Product Launch (Month 6-12)
- Production hardware
- Open-source documentation
- Community building

---

## ğŸ¤ Contributing

This is an open-source project. Contributions welcome!

---

## ğŸ“„ License

MIT License - Free to use, modify, distribute

---

## ğŸ‘¨â€ğŸ’» Author

Diogo Simoes 
Data Scientist | Agricultural Technology Enthusiast  
[GitHub](https://github.com/diogosimoez) | [LinkedIn](https://linkedin.com/in/diogosimoes86)

---

## ğŸ“Š Key Results

### Model Performance
- **ResNet50V2**: 98.74% accuracy (production model)
- **Top-3 Accuracy**: 99.96% (near perfect)
- **Confusion Matrix**: Available in `notebooks/docs/confusion_matrix.png`
- **Per-disease Metrics**: F1-scores 0.96-1.00 across all classes

### Detection Capabilities
- **10 Disease Classes**: 9 tomato diseases + healthy baseline
- **Vision Mode**: Single image â†’ instant diagnosis
- **Sensor Mode**: Environmental risk assessment without images
- **Fusion Mode**: Cross-validated diagnosis with <5% false positive rate

### Visualizations
All training results and comparisons available in `notebooks/docs/`:
- Model comparison charts
- Training curves (ResNet50V2, EfficientNet)
- Confusion matrix
- Per-disease performance metrics

---

**FarmOG Station** - *Bringing precision agriculture to off-grid farmers worldwide* ğŸŒğŸŒ±
